# KNN com Pondera√ß√£o de Dist√¢ncias

Diferentemente do KNN simples, onde cada vizinho tem o mesmo peso na decis√£o, o KNN com pondera√ß√£o de dist√¢ncias atribui pesos aos vizinhos com base na proximidade do ponto de teste. Isso significa que vizinhos mais pr√≥ximos ter√£o maior influ√™ncia na decis√£o do que vizinhos mais distantes.

Essa abordagem permite um modelo mais flex√≠vel e menos sens√≠vel √† escolha do par√¢metro ùëò, tornando a classifica√ß√£o mais robusta.

O c√≥digo fornecido neste reposit√≥rio implementa essa vers√£o do KNN, permitindo comparar a fronteira de decis√£o com a do modelo simples.

## Atividade

- **Objetivos:** Representa√ß√£o do KNN com pondera√ß√£o de dist√¢ncias e entendimento desta abordagem como uma combina√ß√£o de fun√ß√µes radiais.
- **Tarefa:** Estender a implementa√ß√£o anterior incluindo a pondera√ß√£o de dist√¢ncias para a tomada de decis√£o da classifica√ß√£o. De acordo com esta abordagem a resposta do KNN √© representada na forma
  
  $$\hat{y} = \text{sinal} \left( \sum_{i=1}^{N} \alpha_i y_i K(x, x_i) \right)$$ (1)
  
  em que $\alpha_i = 1 \ \forall x_i \in  V_k$, $\alpha_i = 0 \ \forall x_i \notin  V_k$, $V_k$ √© o conjunto dos vizinhos mais pr√≥ximos e $K(x, x_i)$ √© um fun√ß√£o de kernel radial na forma de uma fun√ß√£o Gaussiana.

    Avaliar os efeitos dos par√¢metros do modelo e da fun√ß√£o no desempenho do modelo, considerando a resposta observada da superf√≠cie de separa√ß√£o. Para o exemplo de dados sint√©ticos implementado, a fun√ß√£o Gaussiana (Normal) √© de duas vari√°veis, no entanto, sugere-se que ela seja implementada em sua forma geral:
  
  $$p(x) = \frac{1}{\sqrt{(2\pi)^n |\boldsymbol{\Sigma}|}} \exp \left( -\frac{1}{2} (x - \boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1} (x - \boldsymbol{\mu}) \right)$$ (2)

  em que $n$ √© a dimens√£o de $x$, $\boldsymbol{\Sigma}$ √© a matriz de covari√¢ncias, $|\boldsymbol{\Sigma}|$ o seu determinante e $\boldsymbol{\mu}$ √© o vetor de m√©dias das distribui√ß√µes marginais, conforme apresentado a seguir nas Equa√ß√µes 3 e 4.

  ![image](https://github.com/user-attachments/assets/8a3f3db0-7be3-40d8-9760-28513eb1b2f3) (3)

  ![image](https://github.com/user-attachments/assets/d17e29b4-1358-4265-8983-1244155f4835) (4)

    Para facilitar a implementa√ß√£o, considere a seguinte implementa√ß√£o em $R$ da fun√ß√£o de densidade Normal multivariada:

    ```r
    pdfnvar <- function(x, m, K, n) (1 / (sqrt((2 * pi)^n * det(K)))) * exp(-0.5 * (t(x - m) %*% solve(K) %*% (x - m)))

    em que $\boldsymbol{K} = h\boldsymbol{I}$, sendo assim $h$ o raio da fun√ß√£o Gaussiana.

    Nesta etapa o desempenho do classificador ser√° avaliado de acordo com os par√¢metros $k$ e $h$.
